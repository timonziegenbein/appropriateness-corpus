{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc156af-a4f0-4f42-9bae-c5e1ee4a904d",
   "metadata": {},
   "source": [
    "### This file combines arguments from the UKPConvArg1 corpus and the GAQCropus to create the corpus we use in our annotation study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839fd8a-0f1e-45f1-b4b3-ad4d965aeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import Sentencizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4e97b-7a6a-42c3-a245-f164a62f020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/'\n",
    "ukp2_dir = data_dir+'emnlp2016-empirical-convincingness/data/CSV-format/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4698759-d667-43b3-8365-e8be98be2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_files_ukp2 = glob.glob(ukp2_dir+'*')\n",
    "dfs = []\n",
    "for file in rel_files_ukp2:\n",
    "    if 'LICENSE.txt' not in file:\n",
    "        tmp_df = pd.read_csv(file, sep='\\t', names=['pair_id','gold_label','more_conv_arg','less_conv_arg'])\n",
    "        tmp_df['issue'] = file.split('/')[-1].split('.csv')[0].split('.xml')[0].split('_')[0]\n",
    "        tmp_df['stance'] = file.split('/')[-1].split('.csv')[0].split('.xml')[0].split('_')[1]\n",
    "        dfs.append(tmp_df)\n",
    "df_ukp2 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b3969-a068-49fd-8c1e-1229c1eae1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ukp2['more_conv_id'] = df_ukp2['pair_id'].apply(lambda x: x.split('_')[0])\n",
    "df_ukp2['less_conv_id'] = df_ukp2['pair_id'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6bfb6-3d58-4fa6-bf15-f3eaa582776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ids = {}\n",
    "real_issues = {}\n",
    "for i, row in df_ukp2.iterrows():\n",
    "    if row['more_conv_id'] not in real_ids:\n",
    "        real_ids[row['more_conv_id']] = [row['more_conv_arg'],row['less_conv_arg']]\n",
    "        real_issues[row['more_conv_id']] = row['issue']\n",
    "    elif row['less_conv_id'] not in real_ids:\n",
    "        real_ids[row['less_conv_id']] = [row['more_conv_arg'],row['less_conv_arg']]\n",
    "        real_issues[row['less_conv_id']] = row['issue']\n",
    "    elif len(real_ids[row['more_conv_id']]) == 2:\n",
    "        if row['more_conv_arg'] in real_ids[row['more_conv_id']]:\n",
    "            real_ids[row['more_conv_id']] = [row['more_conv_arg']]\n",
    "        elif row['less_conv_arg'] in real_ids[row['more_conv_id']]:\n",
    "            real_ids[row['more_conv_id']] = [row['less_conv_arg']]\n",
    "    elif len(real_ids[row['less_conv_id']]) == 2:\n",
    "        if row['more_conv_arg'] in real_ids[row['less_conv_id']]:\n",
    "            real_ids[row['less_conv_id']] = [row['more_conv_arg']]\n",
    "        elif row['less_conv_arg'] in real_ids[row['less_conv_id']]:\n",
    "            real_ids[row['less_conv_id']] = [row['less_conv_arg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52dffcf-ca21-4d09-9d67-5c33c7e89e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ukp = pd.DataFrame(data={'#id': real_ids.keys(), 'argument': [x[0] for x in real_ids.values()], 'issue': [real_issues[x] for x in real_ids.keys()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b395a1-929c-4a04-a990-6112ce0aad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check that all the arguments from the Dagstuhl corpus are part of the UKPCorpus\n",
    "df_dagstuhl = pd.read_csv(data_dir+'dagstuhl-15512-argquality-corpus-v2/dagstuhl-15512-argquality-corpus-annotated.csv', sep='\\t', encoding='1254')\n",
    "len(list(set(df_ukp[df_ukp['#id'].isin(df_dagstuhl['#id'])]['#id'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9bdbb-0871-4477-9763-9d680811df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.read_csv(data_dir+'GAQCorpus_split/qa_forums_mixtrain_overlaptest_crowdtest.csv')\n",
    "df_debate = pd.read_csv(data_dir+'GAQCorpus_split/debate_forums_mixtrain_overlaptest_crowdtest.csv')\n",
    "df_review = pd.read_csv(data_dir+'GAQCorpus_split/review_forums_mixtrain_overlaptest_crowdtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1be62-55d3-4f84-8a78-d1e6d39d68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_ukp['#id'].tolist() + df_qa['id'].tolist() + df_debate['id'].tolist() + df_review['id'].tolist()\n",
    "sources = df_ukp['argument'].tolist() + df_qa['text'].tolist() + df_debate['text'].tolist() + df_review['text'].tolist()\n",
    "issues = df_ukp['issue'].tolist() + df_qa['title'].tolist() + df_debate['title'].tolist() + df_review['title'].tolist()\n",
    "batch = [1 for x in range(len(ids))]\n",
    "types = [0 for x in range(len(df_ukp))] + [1 for x in range(len(df_qa))] + [2 for x in range(len(df_debate))] + [3 for x in range(len(df_review))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29243206-d946-480f-bd75-a307e131e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame(data={'id': ids, 'source': sources, 'issue': issues, 'batch': batch, 'types': types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b6e83-0b0c-4319-9d69-5765a3e6595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split into 14 batches for annotaion study\n",
    "cv = StratifiedKFold(n_splits=14, random_state=42, shuffle=True)\n",
    "fold = 0\n",
    "dfs = []\n",
    "for train_idxs, test_idxs in cv.split(corpus_df, corpus_df.types):\n",
    "    fold_df = corpus_df.iloc[test_idxs]\n",
    "    fold_df['batch'] = fold\n",
    "    fold_df.drop(columns=['types'], inplace=True)\n",
    "    fold_df.to_csv(data_dir+'appropriateness-corpus/annotation_dataset_{}.csv'.format(fold), index=False)\n",
    "    fold += 1\n",
    "    dfs.append(fold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddccdc1-530c-4891-a197-b996e5ee7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create full annotation study dataset\n",
    "full_df = pd.concat(dfs)\n",
    "#full_df['id'] = list(range(len(full_df)))\n",
    "#full_df['source'] = full_df['source'].apply(lambda x : x.replace('\\n', '\\\\n'))\n",
    "#full_df.to_csv(data_dir+'appropriateness-corpus/annotation_dataset.csv', index=False)\n",
    "#full_df.to_csv(data_dir+'appropriateness-corpus/annotation_dataset_types.csv', index=False)\n",
    "full_df.to_csv(data_dir+'appropriateness-corpus/annotation_dataset_types_sourceids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde1006-a8c6-4aeb-a202-d94f0d703f2a",
   "metadata": {},
   "source": [
    "### Compute corpus statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbc512-231c-4cf7-95c1-080b6b331557",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(real_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddee36b-dc62-4ca5-80ac-8a6291ef81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([x[0] for x in real_ids.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ad26a-2002-4500-80ac-4037e4a8c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd32b87-131e-4260-b3c3-346cf07c0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_debate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980cc24-bb35-4424-8e95-60f19619fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382b18e-efcd-4d8b-9848-48b0d1f0b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.issue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70896bb0-9308-4a8f-8fc6-9001811c1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_df.issue.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709d752-846b-4123-80ad-3d4a74b2c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(corpus_df.issue.value_counts().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f00b51-1167-46cf-8359-0752b4ab4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(x) for x in corpus_df.source.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435fa6d-72b1-4f3b-9335-511373c0cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "sentencizer = Sentencizer()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ef4ec-1533-46eb-bab8-da49438b272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len([z for z in nlp(x).sents]) for x in corpus_df.source.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2678ad-d7a9-4b50-aef1-15dbff7beee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(tokenizer(x)) for x in corpus_df.source.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2042d5-e4bf-473a-9ccf-a501bf0106b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
